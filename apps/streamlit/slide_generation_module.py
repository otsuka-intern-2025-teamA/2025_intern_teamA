# slide_generation_module.py
# ---------------------------------------------------------
# ã‚¹ãƒ©ã‚¤ãƒ‰ä½œæˆãƒšãƒ¼ã‚¸ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼è¿½åŠ ç‰ˆï¼‰
# - ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šãƒ­ã‚´ï¼æ¡ˆä»¶ä¸€è¦§ã¸æˆ»ã‚‹ï¼ˆå·¦ä¸‹å›ºå®šï¼‰ï¼ä¼æ¥­åï¼ææ¡ˆä»¶æ•°ï¼å±¥æ­´å‚ç…§ä»¶æ•°ï¼å•†æãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆé¸æŠï¼ã‚¯ãƒªã‚¢
# - æœ¬æ–‡ï¼šä¸Šæ®µãƒ˜ãƒƒãƒ€ï¼ˆå·¦ï¼è¦‹å‡ºã—ï¼å³ï¼å€™è£œå–å¾—ãƒœã‚¿ãƒ³ï¼‰ã€
#          å·¦ï¼å•†è«‡è©³ç´°ï¼†å‚è€ƒè³‡æ–™ã‚¢ãƒƒãƒ—ã€å³ï¼LLMææ¡ˆï¼ˆtext_areaã§ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯èƒ½ï¼‰ã€
#          ä¸‹æ®µï¼ç”Ÿæˆã¨ãƒ‰ãƒ©ãƒ•ãƒˆJSON
# - ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰API search_products ãŒç„¡ã„/æœªå¯¾å¿œã§ã‚‚ã€CSVï¼‹ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®ç°¡æ˜“ã‚¹ã‚³ã‚¢ã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
# - â˜… å³ãƒšã‚¤ãƒ³ã¯ text_areaï¼ˆèª­ã¿å–ã‚Šå°‚ç”¨ï¼‰ã§ç¢ºå®Ÿã«ã€Œæ å†…ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã€
# ---------------------------------------------------------

from __future__ import annotations
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
import re
from datetime import datetime

import streamlit as st
import pandas as pd

# å…±é€šã‚¹ã‚¿ã‚¤ãƒ«
from lib.styles import (
    apply_main_styles,
    apply_chat_scroll_script,
    apply_title_styles,
    apply_company_analysis_page_styles,   # ã‚µã‚¤ãƒ‰ãƒãƒ¼åœ§ç¸®/ãƒ­ã‚´ã‚«ãƒ¼ãƒ‰/ä¸‹å¯„ã›CSSã‚’æµç”¨
    apply_slide_generation_page_styles,
    render_sidebar_logo_card,
    render_slide_generation_title,        # ã‚¿ã‚¤ãƒˆãƒ«æç”»ï¼ˆh1.slide-generation-titleï¼‰
)

# æ—¢å­˜ã®ä¼æ¥­åˆ†æç”¨LLMé–¢æ•°
from lib.company_analysis.llm import company_briefing_without_web_search

# APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
from lib.api import get_api_client, api_available, APIError

# AI Agent Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ñ€ĞµĞ·ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¹
from lib.slide_generator import slide_generator

# ç”»åƒ/ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹
PROJECT_ROOT = Path(__file__).parent.parent.parent
LOGO_PATH = PROJECT_ROOT / "data" / "images" / "otsuka_logo.jpg"
ICON_PATH = PROJECT_ROOT / "data" / "images" / "otsuka_icon.png"
PRODUCTS_DIR = PROJECT_ROOT / "data" / "csv" / "products"


# =========================
# ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–
# =========================
def _ensure_session_defaults() -> None:
    ss = st.session_state
    ss.setdefault("selected_project", None)       # æ¡ˆä»¶ä¸€è¦§ã‹ã‚‰é·ç§»æ™‚ã«å…¥ã‚‹
    ss.setdefault("api_error", None)
    ss.setdefault("slide_meeting_notes", "")
    ss.setdefault("uploaded_files_store", [])     # file_uploaderã®ä¿å­˜ç”¨
    ss.setdefault("product_candidates", [])       # [{id, name, category, price, score, reason}]
    ss.setdefault("slide_outline", None)
    ss.setdefault("slide_overview", "")
    ss.setdefault("slide_history_reference_count", 3)  # ç›´è¿‘Nå¾€å¾©å‚ç…§ï¼ˆãƒ‡ãƒ•ã‚©3ï¼‰
    ss.setdefault("slide_top_k", 10)                   # ææ¡ˆä»¶æ•°ï¼ˆãƒ‡ãƒ•ã‚©10ï¼‰
    ss.setdefault("slide_products_dataset", "Auto")    # å•†æãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆé¸æŠ
    ss.setdefault("llm_proposal_text", "")             # LLMã®å‡ºåŠ›


# =========================
# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ/ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåé›†
# =========================
def _list_product_datasets() -> List[str]:
    """productsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªé…ä¸‹ã®ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€åã‚’åˆ—æŒ™ï¼ˆAutoã‚’å…ˆé ­ï¼‰"""
    if not PRODUCTS_DIR.exists():
        return ["Auto"]
    ds = ["Auto"]
    for p in PRODUCTS_DIR.iterdir():
        if p.is_dir():
            ds.append(p.name)
    return ds


def _gather_messages_context(item_id: Optional[str], history_n: int) -> str:
    """ä¼æ¥­åˆ†æã®ç›´è¿‘Nå¾€å¾©ï¼ˆ=2Nç™ºè¨€ï¼‰ã‚’ã¾ã¨ã‚ã¦æ–‡å­—åˆ—åŒ–"""
    if not (item_id and api_available()):
        return ""
    try:
        api = get_api_client()
        msgs = api.get_item_messages(item_id) or []
        take = min(len(msgs), history_n * 2)
        recent = msgs[-take:] if take > 0 else []
        ctx_lines = []
        for m in recent:
            role = m.get("role", "assistant")
            role_j = "ãƒ¦ãƒ¼ã‚¶ãƒ¼" if role == "user" else "ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ"
            ctx_lines.append(f"{role_j}: {m.get('content','')}")
        return "\n".join(ctx_lines)
    except Exception:
        return ""


def _list_uploaded_names(files: List[Any]) -> List[str]:
    names = []
    for f in files or []:
        try:
            names.append(getattr(f, "name", "uploaded_file"))
        except Exception:
            pass
    return names


def _load_products_from_csv(dataset: str) -> pd.DataFrame:
    """
    å•†æCSVã‚’ãƒ­ãƒ¼ãƒ‰ï¼ˆå­˜åœ¨ã‚«ãƒ©ãƒ ãŒç„¡ã‘ã‚Œã°ä½œæˆï¼‰
    æœŸå¾…ã‚«ãƒ©ãƒ : id(ç„¡ã‘ã‚Œã°ç”Ÿæˆ), name, category, price, description, tags
    """
    frames: List[pd.DataFrame] = []
    if not PRODUCTS_DIR.exists():
        return pd.DataFrame()

    def _read_csvs(folder: Path):
        for csvp in folder.glob("*.csv"):
            try:
                df = pd.read_csv(csvp)
                for col in ["name", "category", "price", "description", "tags"]:
                    if col not in df.columns:
                        df[col] = None
                if "id" not in df.columns:
                    df["id"] = [f"{csvp.stem}-{i+1}" for i in range(len(df))]
                frames.append(df[["id", "name", "category", "price", "description", "tags"]])
            except Exception:
                continue

    if dataset == "Auto":
        for sub in PRODUCTS_DIR.iterdir():
            if sub.is_dir():
                _read_csvs(sub)
        _read_csvs(PRODUCTS_DIR)
    else:
        target = PRODUCTS_DIR / dataset
        if target.exists() and target.is_dir():
            _read_csvs(target)

    if not frames:
        return pd.DataFrame()
    return pd.concat(frames, ignore_index=True)


# =========================
# æ¤œç´¢ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆç°¡æ˜“ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ï¼‰
# =========================
def _simple_tokenize(text: str) -> List[str]:
    text = str(text or "").lower()
    text = re.sub(r"[^a-z0-9\u3040-\u30ff\u4e00-\u9fff]+", " ", text)
    toks = text.split()
    return [t for t in toks if len(t) >= 2]


def _fallback_rank_products(
    notes: str,
    messages_ctx: str,
    products_df: pd.DataFrame,
    top_k: int
) -> List[Dict[str, Any]]:
    """å•†è«‡ãƒ¡ãƒ¢ï¼‹å±¥æ­´ã®èªå¥ä¸€è‡´ã§ç´ æœ´ã«ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°"""
    if products_df.empty:
        return []

    query_text = (notes or "") + "\n" + (messages_ctx or "")
    q_tokens = _simple_tokenize(query_text)
    if not q_tokens:
        out = []
        for _, row in products_df.head(top_k).iterrows():
            out.append({
                "id": row.get("id"),
                "name": row.get("name"),
                "category": row.get("category"),
                "price": row.get("price"),
                "score": 0.0,
                "reason": "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä¸è¶³ã®ãŸã‚å…ˆé ­å€™è£œï¼ˆæš«å®šï¼‰",
            })
        return out

    def _row_text(row) -> str:
        return " ".join([
            str(row.get("name") or ""),
            str(row.get("category") or ""),
            str(row.get("description") or ""),
            str(row.get("tags") or ""),
        ]).lower()

    scored: List[Tuple[float, Dict[str, Any]]] = []
    for _, row in products_df.iterrows():
        t = _row_text(row)
        score = 0.0
        for tok in q_tokens:
            if tok in t:
                score += 1.0
        reason = f"ä¸€è‡´èªå¥æ•°={int(score)}" if score > 0 else "ä¸€è‡´ãªã—ï¼ˆä½ã‚¹ã‚³ã‚¢ï¼‰"
        scored.append((score, {
            "id": row.get("id"),
            "name": row.get("name"),
            "category": row.get("category"),
            "price": row.get("price"),
            "score": round(float(score), 2),
            "reason": reason,
        }))

    scored.sort(key=lambda x: (x[0], str(x[1]["name"]).lower()), reverse=True)
    return [d for _, d in scored[:top_k]]


# =========================
# LLM ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆï¼†å®Ÿè¡Œ
# =========================
def _build_llm_prompt_for_proposals(
    company: str,
    meeting_notes: str,
    messages_ctx: str,
    uploads_names: List[str],
    candidates: List[Dict[str, Any]],
    want: int,
) -> str:
    cand_lines = []
    for c in candidates:
        cand_lines.append(
            f"- name: {c.get('name')} | category: {c.get('category')} | price: {c.get('price')} | hint: {c.get('reason')}"
        )
    uploads_line = ", ".join(uploads_names) if uploads_names else "ï¼ˆãªã—ï¼‰"
    ctx_block = messages_ctx.strip() or "ï¼ˆç›´è¿‘ã®ãƒãƒ£ãƒƒãƒˆå±¥æ­´ãªã—ï¼‰"

    prompt = f"""ã‚ãªãŸã¯B2Bææ¡ˆã®ãƒ—ãƒªã‚»ãƒ¼ãƒ«ã‚¹ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®æƒ…å ±ã‚’ä½¿ã„ã€**{company}** å‘ã‘ã®ææ¡ˆå•†æã‚’ **æœ€å¤§ {want} ä»¶**ã€æ—¥æœ¬èªMarkdownã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

# ä¾é ¼
- ã€Œææ¡ˆã®è¦æ—¨ï¼ˆ2ã€œ3è¡Œï¼‰ã€ã‚’æœ€åˆã«ã€‚
- ãã®å¾Œã« ã€Œæ¨å¥¨å•†æï¼ˆmax {want} ä»¶ï¼‰ã€ã‚’ã€**ç®‡æ¡æ›¸ã**ã§ä»¥ä¸‹ã®å½¢å¼ã§è©³è¿°:
  - **å•†æå**ï¼ˆã‚«ãƒ†ã‚´ãƒªã€æ¦‚ç®—ä¾¡æ ¼ï¼‰ â€” ã“ã®æ¡ˆä»¶ã§ã®é©åˆç†ç”±ï¼ˆæ¥­å‹™ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ/å°å…¥å®¹æ˜“æ€§/å‰ææ¡ä»¶ãªã©ï¼‰
- æœ€å¾Œã«ã€Œæ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆæ‰“ã¡æ‰‹æ¡ˆï¼‰ã€ã¨ã—ã¦ã€2ã€œ3é …ç›®ã€‚

# å…¥åŠ›ï¼ˆå•†è«‡ãƒ¡ãƒ¢æŠœç²‹ï¼‰
{meeting_notes.strip() or "ï¼ˆæœªå…¥åŠ›ï¼‰"}

# å‚è€ƒè³‡æ–™ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åï¼‰
{uploads_line}

# ç›´è¿‘ãƒãƒ£ãƒƒãƒˆå±¥æ­´ï¼ˆä¼æ¥­åˆ†æï¼‰
{ctx_block}

# å€™è£œã‚«ã‚¿ãƒ­ã‚°ï¼ˆç¤¾å†…å•†æï¼‰
{chr(10).join(cand_lines)}

# æ³¨æ„
- å€™è£œã‚«ã‚¿ãƒ­ã‚°ã®ä¸­ã‹ã‚‰é¸ã³ã€å¿…è¦ãŒã‚ã‚Œã°è¤‡æ•°ã‚’çµ„ã¿åˆã‚ã›ã¦ã‚‚ã‚ˆã„ã€‚
- ã‚«ã‚¿ãƒ­ã‚°ã«ç„¡ã„è¦ç´ æŠ€è¡“ã‚„ä¸€èˆ¬è«–ã«ä¾å­˜ã—ã™ããªã„ã“ã¨ã€‚
- èª‡å¼µã‚’é¿ã‘ã€æ ¹æ‹ ãƒ™ãƒ¼ã‚¹ã§å…·ä½“çš„ã«ã€‚
- å‡ºåŠ›ã¯**æ—¥æœ¬èªMarkdown**ã®ã¿ã€‚å‰ç½®ãã‚„ãƒ¡ã‚¿ã‚³ãƒ¡ãƒ³ãƒˆã¯ç¦æ­¢ã€‚
"""
    return prompt


def _run_llm_proposal(
    company: str,
    meeting_notes: str,
    item_id: Optional[str],
    history_n: int,
    candidates: List[Dict[str, Any]],
    uploads: List[Any],
    want: int,
) -> str:
    messages_ctx = _gather_messages_context(item_id, history_n)
    uploads_names = _list_uploaded_names(uploads)
    prompt = _build_llm_prompt_for_proposals(
        company=company,
        meeting_notes=meeting_notes,
        messages_ctx=messages_ctx,
        uploads_names=uploads_names,
        candidates=candidates,
        want=want,
    )
    try:
        result = company_briefing_without_web_search(company, prompt, "")
        return str(result)
    except Exception as e:
        return f"LLMå®Ÿè¡Œã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"


# =========================
# å€™è£œæ¤œç´¢ï¼ˆAPI or ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
# =========================
def _search_product_candidates(
    company: str,
    item_id: Optional[str],
    meeting_notes: str,
    top_k: int,
    history_n: int,
    dataset: str,
    uploaded_files: List[Any],
) -> List[Dict[str, Any]]:
    if api_available():
        try:
            api = get_api_client()
            if hasattr(api, "search_products"):
                try:
                    return api.search_products(
                        company=company,
                        query=meeting_notes,
                        top_k=top_k,
                        context=_gather_messages_context(item_id, history_n),
                        dataset=dataset,
                        uploads=", ".join(_list_uploaded_names(uploaded_files)),
                    ) or []
                except TypeError:
                    return api.search_products(company=company, query=meeting_notes, top_k=top_k) or []
        except APIError as e:
            st.error(f"âŒ å•†å“å€™è£œå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        except Exception:
            pass

    products_df = _load_products_from_csv(dataset)
    return _fallback_rank_products(
        notes=meeting_notes,
        messages_ctx=_gather_messages_context(item_id, history_n),
        products_df=products_df,
        top_k=top_k,
    )


# =========================
# ãƒ‰ãƒ©ãƒ•ãƒˆä½œæˆ
# =========================
def _make_outline_preview(company: str, meeting_notes: str, selected_products: List[Dict[str, Any]], overview: str) -> Dict[str, Any]:
    return {
        "title": f"{company} å‘ã‘ææ¡ˆè³‡æ–™ï¼ˆãƒ‰ãƒ©ãƒ•ãƒˆï¼‰",
        "overview": overview,
        "sections": [
            {"h2": "1. ã‚¢ã‚¸ã‚§ãƒ³ãƒ€", "bullets": ["èƒŒæ™¯", "èª²é¡Œæ•´ç†", "ææ¡ˆæ¦‚è¦", "å°å…¥åŠ¹æœ", "å°å…¥è¨ˆç”»", "æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"]},
            {"h2": "2. èƒŒæ™¯", "bullets": [f"{company}ã®äº‹æ¥­æ¦‚è¦ï¼ˆè¦ç´„ï¼‰", "å¸‚å ´å‹•å‘ãƒ»ç«¶åˆçŠ¶æ³ï¼ˆæŠœç²‹ï¼‰"]},
            {"h2": "3. ç¾çŠ¶ã®èª²é¡Œï¼ˆä»®èª¬ï¼‰", "bullets": ["ç”Ÿç”£æ€§/ã‚³ã‚¹ãƒˆ/å“è³ª/ã‚¹ãƒ”ãƒ¼ãƒ‰ã®è¦³ç‚¹ã‹ã‚‰3ã€œ5ç‚¹"]},
            {"h2": "4. ææ¡ˆæ¦‚è¦", "bullets": ["æœ¬ææ¡ˆã®ç›®çš„ï¼ç‹™ã„", "å…¨ä½“ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ˆé«˜ãƒ¬ãƒ™ãƒ«ï¼‰"]},
            {"h2": "5. æ¨å¥¨ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå€™è£œï¼‰", "bullets": [f"{len(selected_products)}ä»¶ã®å•†æå€™è£œã‚’æ•´ç†ãƒ»æ¯”è¼ƒ"]},
            {"h2": "6. å°å…¥åŠ¹æœï¼ˆå®šé‡/å®šæ€§ï¼‰", "bullets": ["KPIè¦‹è¾¼ã¿ / åŠ¹æœè©¦ç®—ã®æ–¹é‡"]},
            {"h2": "7. å°å…¥ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æ¡ˆ", "bullets": ["PoC â†’ æœ¬å°å…¥ / ä½“åˆ¶ãƒ»å½¹å‰²åˆ†æ‹…"]},
        ],
        "meeting_notes_digest": meeting_notes[:300] + ("..." if len(meeting_notes) > 300 else ""),
        "products": [
            {"id": p.get("id"), "name": p.get("name"), "category": p.get("category"),
             "price": p.get("price"), "reason": p.get("reason")}
            for p in selected_products
        ],
    }


def _get_company_report_from_messages(item_id: Optional[str]) -> str:
    """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ Ğ¾Ñ‚Ñ‡ĞµÑ‚ Ğ¾ ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¸ Ğ¸Ğ· ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ Ğ² Ğ±Ğ°Ğ·Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…"""
    if not item_id or not api_available():
        return "ä¼æ¥­ãƒ¬ãƒãƒ¼ãƒˆæƒ…å ±ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚"
    
    try:
        api = get_api_client()
        # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°
        messages = api.get_item_messages(item_id, limit=20)
        
        if not messages:
            return "ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"
        
        # Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ğ¸Ğ· ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹
        report_parts = []
        for msg in messages:
            if msg.get("role") == "assistant":
                content = msg.get("content", "")
                if content and len(content) > 50:  # Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€ÑƒĞµĞ¼ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ
                    report_parts.append(content)
        
        if report_parts:
            # ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµĞ¼ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ 3 ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚Ğ°
            return "\n\n".join(report_parts[-3:])
        else:
            return "ä¼æ¥­åˆ†æã®çµæœãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚"
            
    except Exception as e:
        st.warning(f"ä¼æ¥­ãƒ¬ãƒãƒ¼ãƒˆã®å–å¾—ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return "ä¼æ¥­ãƒ¬ãƒãƒ¼ãƒˆã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"


# =========================
# ãƒ¡ã‚¤ãƒ³æç”»
# =========================
def render_slide_generation_page():
    """ã‚¹ãƒ©ã‚¤ãƒ‰ä½œæˆãƒšãƒ¼ã‚¸ã‚’ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ï¼ˆå³ãƒšã‚¤ãƒ³ã¯ text_area ã§æ å†…ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ï¼‰"""
    _ensure_session_defaults()

    try:
        st.set_page_config(
            page_title="ã‚¹ãƒ©ã‚¤ãƒ‰ä½œæˆ",
            page_icon=str(ICON_PATH),
            layout="wide",
            initial_sidebar_state="expanded",
        )
    except Exception:
        pass

    # ã‚¹ã‚¿ã‚¤ãƒ«
    apply_main_styles(hide_sidebar=False, hide_header=True)
    apply_chat_scroll_script()
    apply_title_styles()
    apply_company_analysis_page_styles()  # ã‚µã‚¤ãƒ‰ãƒãƒ¼å…±é€š
    apply_slide_generation_page_styles()  # ã‚¿ã‚¤ãƒˆãƒ«ä½ç½®ãªã©

    # æ¡ˆä»¶ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
    pj = st.session_state.get("selected_project")
    if pj:
        title_text = f"ã‚¹ãƒ©ã‚¤ãƒ‰ä½œæˆ - {pj['title']} / {pj['company']}"
        company_internal = pj.get("company", "")
        item_id = pj.get("id")
    else:
        title_text = "ã‚¹ãƒ©ã‚¤ãƒ‰ä½œæˆ"
        company_internal = ""
        item_id = None

    # ---------- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ----------
    with st.sidebar:
        render_sidebar_logo_card(LOGO_PATH)

        st.markdown("### è¨­å®š")
        st.text_input("ä¼æ¥­å", value=company_internal, key="slide_company_input", disabled=True)

        st.session_state.slide_top_k = st.number_input(
            "ææ¡ˆä»¶æ•°",
            min_value=3, max_value=20, value=st.session_state.slide_top_k, step=1,
            key="slide_top_k_input",
        )

        st.session_state.slide_history_reference_count = st.selectbox(
            "å±¥æ­´å‚ç…§ä»¶æ•°ï¼ˆå¾€å¾©ï¼‰",
            options=list(range(1, 11)),
            index=max(0, st.session_state.slide_history_reference_count - 1),
            key="slide_history_count_select",
            help="ä¼æ¥­åˆ†æã®ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®ç›´è¿‘Nå¾€å¾©ã‚’æ–‡è„ˆã¨ã—ã¦ä½¿ç”¨",
        )

        datasets = _list_product_datasets()
        st.session_state.slide_products_dataset = st.selectbox(
            "å•†æãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ",
            options=datasets,
            index=datasets.index(st.session_state.slide_products_dataset) if st.session_state.slide_products_dataset in datasets else 0,
            key="slide_products_dataset_select",
            help="data/csv/products/ é…ä¸‹ã®ãƒ•ã‚©ãƒ«ãƒ€ã€‚Autoã¯è‡ªå‹•é¸æŠã€‚",
        )

        st.markdown("---")
        st.markdown("### AIè¨­å®š")
        
        # API Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸
        use_tavily_api = st.checkbox(
            "TAVILY APIä½¿ç”¨",
            value=False,
            key="use_tavily_api",
            help="TAVILY APIã‚’ä½¿ç”¨ã—ã¦å•†å“æƒ…å ±ã‚’å¼·åŒ–"
        )
        
        use_gpt_api = st.checkbox(
            "GPT APIä½¿ç”¨",
            value=False,
            key="use_gpt_api",
            help="GPT APIã‚’ä½¿ç”¨ã—ã¦ã‚¹ãƒ©ã‚¤ãƒ‰å†…å®¹ã‚’ç”Ÿæˆ"
        )
        
        if use_tavily_api:
            tavily_uses = st.number_input(
                "TAVILY APIå‘¼ã³å‡ºã—å›æ•°ï¼ˆå•†å“ã”ã¨ï¼‰",
                min_value=1,
                max_value=10,
                value=3,
                key="tavily_uses",
                help="å„å•†å“ã«å¯¾ã—ã¦TAVILY APIã‚’ä½•å›å‘¼ã³å‡ºã™ã‹"
            )
        else:
            tavily_uses = 3

        sidebar_clear = st.button("ã‚¯ãƒªã‚¢", use_container_width=True, help="å€™è£œã¨LLMå‡ºåŠ›ã‚’ç”»é¢å†…ã§ã‚¯ãƒªã‚¢")

        st.markdown("<div class='sidebar-bottom'>", unsafe_allow_html=True)
        if st.button("â† æ¡ˆä»¶ä¸€è¦§ã«æˆ»ã‚‹", use_container_width=True):
            st.session_state.current_page = "æ¡ˆä»¶ä¸€è¦§"
            st.session_state.page_changed = True
            st.rerun()
        st.markdown("</div>", unsafe_allow_html=True)

    # ---------- ã‚¿ã‚¤ãƒˆãƒ« ----------
    render_slide_generation_title(title_text)

    # ---------- è¦‹å‡ºã—è¡Œï¼ˆå·¦ï¼è¦‹å‡ºã— / å³ï¼å€™è£œå–å¾—ãƒœã‚¿ãƒ³ï¼‰ ----------
    head_l, head_r = st.columns([8, 2])
    with head_l:
        st.subheader("1. å•†å“ææ¡ˆ")
    with head_r:
        search_btn = st.button("å€™è£œã‚’å–å¾—", use_container_width=True)

    # ====================== 1. å•†å“ææ¡ˆï¼ˆå·¦å³2ãƒšã‚¤ãƒ³ï¼‰ ======================
    left, right = st.columns([5, 7], gap="large")

    # ---- å·¦ï¼šå•†è«‡è©³ç´° + å‚è€ƒè³‡æ–™
    with left:
        st.markdown("**â— å•†è«‡ã®è©³ç´°**")
        st.text_area(
            label="å•†è«‡ã®è©³ç´°",
            key="slide_meeting_notes",
            height=160,
            label_visibility="collapsed",
            placeholder="ä¾‹ï¼šæ¥æœŸã®éœ€è¦äºˆæ¸¬ç²¾åº¦å‘ä¸Šã¨åœ¨åº«æœ€é©åŒ–ã€‚PoCã‹ã‚‰æ®µéšå°å…¥â€¦ ãªã©",
        )

        st.markdown("**â— å‚è€ƒè³‡æ–™**")
        uploads = st.file_uploader(
            label="å‚è€ƒè³‡æ–™ï¼ˆä»»æ„ï¼‰",
            type=["pdf", "pptx", "docx", "csv", "png", "jpg", "jpeg"],
            accept_multiple_files=True,
            key="slide_uploader",
            label_visibility="collapsed",
            help="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰è³‡æ–™ã¯ç‰¹å¾´æŠ½å‡º/è¦ç´„ã«åˆ©ç”¨ã™ã‚‹æƒ³å®šï¼ˆç¾çŠ¶ã¯ãƒ•ã‚¡ã‚¤ãƒ«åã®ã¿æ–‡è„ˆåŒ–ï¼‰ã€‚",
        )
        if uploads:
            st.session_state.uploaded_files_store = uploads
            st.success(f"{len(uploads)} ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å—ã‘ä»˜ã‘ã¾ã—ãŸã€‚")
        elif st.session_state.uploaded_files_store:
            st.caption(f"å‰å›ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿: {len(st.session_state.uploaded_files_store)} ãƒ•ã‚¡ã‚¤ãƒ«")

    # ---- å³ï¼šLLMææ¡ˆï¼ˆtext_areaã§æ å†…ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ï¼‰
    with right:
        st.markdown("**â— LLMã«ã‚ˆã‚‹ææ¡ˆ**")

        # ã€Œå€™è£œã‚’å–å¾—ã€ã‚¯ãƒªãƒƒã‚¯ã§ï¼šå€™è£œæ¤œç´¢ â†’ LLMå®Ÿè¡Œ â†’ å‡ºåŠ›ä¿å­˜
        if search_btn:
            if not company_internal.strip():
                st.error("ä¼æ¥­ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚æ¡ˆä»¶ä¸€è¦§ã‹ã‚‰ä¼æ¥­ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚")
            else:
                with st.spinner("å€™è£œã‚’æ¤œç´¢ä¸­â€¦"):
                    candidates = _search_product_candidates(
                        company=company_internal,
                        item_id=item_id,
                        meeting_notes=st.session_state.slide_meeting_notes or "",
                        top_k=int(st.session_state.slide_top_k),
                        history_n=int(st.session_state.slide_history_reference_count),
                        dataset=st.session_state.slide_products_dataset,
                        uploaded_files=st.session_state.uploaded_files_store,
                    )
                st.session_state.product_candidates = candidates

                with st.spinner("LLMã§ææ¡ˆæ–‡ã‚’ä½œæˆä¸­â€¦"):
                    st.session_state.llm_proposal_text = _run_llm_proposal(
                        company=company_internal,
                        meeting_notes=st.session_state.slide_meeting_notes or "",
                        item_id=item_id,
                        history_n=int(st.session_state.slide_history_reference_count),
                        candidates=candidates,
                        uploads=st.session_state.uploaded_files_store,
                        want=int(st.session_state.slide_top_k),
                    )

        if sidebar_clear:
            st.session_state.product_candidates = []
            st.session_state.llm_proposal_text = ""
            st.info("å€™è£œã¨LLMå‡ºåŠ›ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸã€‚")

        # â˜… ã“ã“ãŒç¢ºå®Ÿã«æ å†…ã«è¡¨ç¤ºãƒ»ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«
        st.text_area(
            label="LLMææ¡ˆï¼ˆè¡¨ç¤ºå°‚ç”¨ï¼‰",
            value=st.session_state.llm_proposal_text or "å€™è£œã‚’å–å¾—ã™ã‚‹ã¨ã€ã“ã“ã«LLMã®ææ¡ˆçµæœï¼ˆè¦æ—¨ãƒ»æ¨å¥¨å•†æãƒ»æ¬¡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼‰ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚",
            height=370,                       # å·¦å´ã®é«˜ã•ã¨ãƒãƒ©ãƒ³ã‚¹ã‚’åˆã‚ã›ã‚‹
            key="llm_proposal_viewer",
            label_visibility="collapsed",
            disabled=True,                    # èª­ã¿å–ã‚Šå°‚ç”¨
        )

    st.divider()

    # ====================== 2. ã‚¹ãƒ©ã‚¤ãƒ‰ç”Ÿæˆ ======================
    st.subheader("2. ã‚¹ãƒ©ã‚¤ãƒ‰ç”Ÿæˆ")

    row_l, row_r = st.columns([8, 2], vertical_alignment="center")
    with row_l:
        st.session_state.slide_overview = st.text_input(
            "æ¦‚èª¬ï¼ˆä»»æ„ï¼‰",
            value=st.session_state.slide_overview or "",
            placeholder="ä¾‹ï¼šåœ¨åº«æœ€é©åŒ–ã‚’ä¸­å¿ƒã«ã€éœ€è¦äºˆæ¸¬ã¨è£œå……è¨ˆç”»ã®é€£æºã‚’ææ¡ˆâ€¦",
        )
    with row_r:
        gen_btn = st.button("ç”Ÿæˆ", type="primary", use_container_width=True)

    if gen_btn:
        if not company_internal.strip():
            st.error("ä¼æ¥­ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        else:
            selected = list(st.session_state.product_candidates or [])
            outline = _make_outline_preview(
                company_internal,
                st.session_state.slide_meeting_notes or "",
                selected,
                st.session_state.slide_overview or "",
            )
            st.session_state.slide_outline = outline
            st.success("ä¸‹æ›¸ãã‚’ä½œæˆã—ã¾ã—ãŸã€‚")

    if st.session_state.slide_outline:
        with st.expander("ä¸‹æ›¸ããƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆJSONï¼‰", expanded=True):
            st.json(st.session_state.slide_outline)
        
        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ ĞºĞ½Ğ¾Ğ¿ĞºÑƒ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ñ€ĞµĞ·ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸
        st.markdown("---")
        st.subheader("3. ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆ")
        
        col1, col2 = st.columns([8, 2])
        with col1:
            st.info("ä¸‹æ›¸ããŒä½œæˆã•ã‚Œã¾ã—ãŸã€‚ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆã™ã‚‹ã«ã¯ä¸‹ã®ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚")
        with col2:
            generate_ppt_btn = st.button("ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆ", type="primary", use_container_width=True)
        
        if generate_ppt_btn:
            with st.spinner("AI AgentãŒãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆä¸­..."):
                try:
                    # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ¾Ñ‚Ñ‡ĞµÑ‚ Ğ¾ ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¸ Ğ¸Ğ· ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹
                    company_report = _get_company_report_from_messages(item_id)
                    
                    # Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ñ€ĞµĞ·ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ
                    pptx_bytes = slide_generator.generate_presentation(
                        company_name=company_internal,
                        company_report=company_report,
                        user_input=st.session_state.slide_meeting_notes or "",
                        llm_proposal=st.session_state.llm_proposal_text or "",
                        additional_instructions=st.session_state.slide_overview or "",
                        use_tavily_api=st.session_state.get("use_tavily_api", False),
                        use_gpt_api=st.session_state.get("use_gpt_api", False),
                        tavily_uses=st.session_state.get("tavily_uses", 3)
                    )
                    
                    # ĞŸÑ€ĞµĞ´Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞµĞ¼ Ñ„Ğ°Ğ¹Ğ» Ğ´Ğ»Ñ ÑĞºĞ°Ñ‡Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ
                    st.success("ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸï¼")
                    
                    filename = f"{company_internal}_ææ¡ˆè³‡æ–™_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pptx"
                    st.download_button(
                        label="ğŸ“¥ ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=pptx_bytes,
                        file_name=filename,
                        mime="application/vnd.openxmlformats-officedocument.presentationml.presentation",
                        use_container_width=True
                    )
                    
                except Exception as e:
                    st.error(f"ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                    st.exception(e)
